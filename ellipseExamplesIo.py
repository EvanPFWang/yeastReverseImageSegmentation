import imageio
import imageio.v2 as iio2  #imageio‑v3 friendly import
import imageio.v3 as iio3

from sklearn.decomposition import PCA
import numpy as np, seaborn as sns
from cv2.detail import strip
from numpy import ndarray
from sklearn.cluster import MiniBatchKMeans
from skimage.color import lab2rgb,  deltaE_ciede2000

from skimage.draw import ellipse

from typing import List

import os
import cv2
import time
import math

import tifffile as tiff
import matplotlib.pyplot as plt
from skimage.color import label2rgb  #nice categorical colouring
from skimage.color import rgb2gray
from pathlib import Path

print("Done Importing")

notebook_directory = os.getcwd()

print(f"Notebook directory: {notebook_directory}")


_DOUBLE_EPS  = np.finfo(np.float64).eps     # ≈ 2.22e‑16
_DOUBLE_TINY = np.finfo(np.float64).tiny    # ≈ 2.23e‑308


import os
import json
import time
from typing import Tuple, Dict, Any

import cv2
import imageio
import numpy as np

"""ellipseExamplesIo.py

Routines for saving, loading, visualising and benchmarking the label
images generated by *EllipseGeneralForm*.  These helpers depend on the core
functions living in the companion module (see `ellipse_params_to_general_form`,
`create_ellipse_mask_vectorized`, `create_ellipse_mask_mathematical`, and
`generate_uint8_labels`).
"""
#If you saved the core under a module name, replace
#the relative import accordingly.

# The following imports assume this helper lives in the same package / notebook
# as the previously‑defined numerical core


from  ellipseMath import (
    ellipse_params_to_general_form,
    create_ellipse_mask_vectorized_perturbed,
    generate_uint8_labels,
    generate_uint8_labels_cv2,
)

__all__ = [
    "save_uint8_labels",
    "load_uint8_labels",
    "visualize_uint8_labels",
    #"compare_mask_generation_methods", removed
    "complete_pipeline",
    "inspect_uint8_output",
    "generate_uint8_labels_cv2",
]


#                                                                           -
# I/O HELPERS
#                                                                           -

def save_uint8_labels(uint8_labels: np.ndarray,dimensions,offset, base_filename: str) -> Dict[str, Any]:
    """Save a uint8 label map in four companion formats.

    1. Raw binary (`*.uint8`)
    2. NumPy array (`*.npy`)
    3. 8‑bit PNG (`*_labels.png`)
    4. JSON metadata (`*_metadata.json`)

    Parameters

    uint8_labels : np.ndarray, dtype ``np.uint8``
        The label image to write.
    base_filename : str
        Path *without* extension; the four outputs will append their own
        extensions as shown above.
    """
    if uint8_labels.dtype != np.uint8:
        raise TypeError("uint8_labels must be of dtype uint8")

    # 1 — raw canvased  binary
    uint8_labels.tofile(f"{base_filename}.uint8")
    print(f"Saved raw binary: {base_filename}.uint8")

    # 2 — NumPy .npy
    np.save(f"{base_filename}.npy", uint8_labels)
    print(f"Saved NumPy array: {base_filename}.npy")

    # 3 — PNG (palettised if desired)
    imageio.imwrite(f"{base_filename}_labels.png", uint8_labels)
    print(f"Saved PNG: {base_filename}_labels.png")

    # 4 — simple metadata
    metadata: Dict[str, Any] = {
        "width": dimensions[0],
        "height": dimensions[1],
        "dtype": "uint8",
        "unique_labels": np.unique(uint8_labels).tolist(),
        "max_label": int(uint8_labels.max()),
        "offset": offset
    }
    with open(f"{base_filename}_metadata.json", "w", encoding="utf-8") as f:
        json.dump(metadata, f, indent=2)
    print(f"Saved metadata: {base_filename}_metadata.json")

    return metadata


def load_uint8_labels(filename: str, width: int, height: int) -> np.ndarray:
    """Load a raw ``*.uint8`` file previously written by
    :func:`save_uint8_labels`.
    """
    flat_array = np.fromfile(filename, dtype=np.uint8)
    return flat_array.reshape((height, width))

def n_spaced_lab(n:int=9):
    """
    Generate perceptually spaced cluster centers in array of shape (n_clusters,3) with Lab coords
    """
    rng = np.random.default_rng(n)
    lab = rng.uniform([0, -40, -40],  # L* >= 0
                      [100, 40, 40],  # cut a*,b* to a sensible gamut‑like cube
                      size=(5000, 3))
    k = MiniBatchKMeans(n_clusters=n, batch_size=1536).fit(lab)
    return k.cluster_centers_.astype(np.float32)

def order_for_gradient(lab):
    """Return an index array giving a ΔE‑smoothed order."""
    # PCA
    pc1 = PCA(n_components=1).fit_transform(lab).ravel()
    order = np.argsort(pc1)
    # ΔE check
    from skimage.color import deltaE_ciede2000
    lab_sorted = lab[order]
    if (deltaE_ciede2000(lab_sorted[:-1], lab_sorted[1:]).max() > 25):
        order = np.argsort(lab[:,0])   # fallback: by lightness
    return order
def gradient_palette(n_colors, background_dark=True):
    lab = n_spaced_lab(n_colors)
    idx = order_for_gradient(lab)
    if background_dark:
        idx = idx[np.argsort(lab[idx,0])]      # ascending L*: darkest first
    ordered_lab = lab[idx]
    rgb_u8 = np.clip(lab2rgb(ordered_lab[None])[0] * 255, 0, 255).astype(np.uint8)
    return rgb_u8                              #

def colormap_for_cells(unique_cell_ids):#Default 0-(9+1)
    n = unique_cell_ids.max()         #assumes labels 1…n
    print(unique_cell_ids)
    palette = gradient_palette(n+1)   # returns n+1 rows
    print(palette)
    return palette[unique_cell_ids]

def palette_to_strip(rgb_float, h,thickness,
                   out_file="palette.png"):
    """
    rgb_float   : (n,3) array in 0-255 *float*
    h           : image height in pixels
    thickness   : width in pixels of the strip
    """
    print("HORSSSEEEEEE")
    rgb_u8 = np.clip(np.round(rgb_float), 0, 255).astype(np.uint8)

    #generate interpolation anchors
    anchors = np.linspace(0, h - 1, len(rgb_float), dtype=np.float32)
    base = np.arange(h, dtype=np.float32)

    #build a 1-pixel-wide column, then widen
    col = np.empty((h, 1, 3), dtype=np.uint8)
    for ch in range(3):  # R, G, B channels
        col[:, 0, ch] = np.interp(base, anchors, rgb_u8[:, ch]).round().astype(
            np.uint8)
    #tile to desired thickness - i had it upside down so flip it vertically - then save
    img = np.flipud(np.tile(col, (1, thickness, 1)))
    iio3.imwrite(out_file, img)
    return img
def colormap_for_cells(unique_labels):
    n = unique_labels.max()+1        # assumes labels 1…n, 0=background
    palette = gradient_palette(n)   # returns n+1 rows
    return palette[unique_labels]   # broadcast lookup

_DEFAULT_CELL_IDS   =   np.array(range(0,9+1),  np.uint8)
_DEFAULT_COLORMAP    =   colormap_for_cells(_DEFAULT_CELL_IDS)
_FALSE_YELLOW   =   tuple(int("#CFCF00".lstrip('#')[i:i+2], 16) for i in (0, 2, 4))
def visualize_uint8_labels(uint8_labels: np.ndarray,    metadata:   Dict,colormap:  Dict) -> np.ndarray:
    """Turn a label map into an RGB image using a lookup table.
    Extra labels beyond the length of the palette receive random colours.
    """

    label_idx,width,height   =   metadata["unique_labels"], metadata["width"], metadata["height"]

    if colormap is None:
        colormap = _DEFAULT_COLORMAP.copy()


    max_label = int(uint8_labels.max())
    if max_label >= len(colormap):
        n_extra = max_label + 1 - len(colormap)
        extra = np.random.randint(50, 256, (n_extra, 3), dtype=np.uint8)
        colormap = np.vstack([colormap, extra])

    return colormap[uint8_labels]


#                                                                           -
# BENCHMARK / DEMO UTILITIES
#                                                                           -

#unnecessary after using theese to test ellipses
"""
def _mask_pair(w: int, h: int, center_x: float, center_y: float, a: float, b: float, angle: float):
    coeffs = ellipse_params_to_general_form(center_x, center_y, a, b, angle)
    mask_math = create_ellipse_mask_mathematical(w, h, coeffs)
    mask_vec  = create_ellipse_mask_vectorized(w, h, coeffs)
    return mask_math, mask_vec


def compare_mask_generation_methods() -> None:
    Benchmark pixel‑loop vs. vectorised mask generators for a single ellipse.

    w, h = 128, 128
    center_x, center_y = 64, 64
    a, b = 20, 15
    angle = 30

    print("=== Comparing Ellipse Mask Generation Methods ===")
    print(f"Image size: {w}x{h}")
    print(f"Ellipse: center=({center_x},{center_y}), axes=({a},{b}), rotation={angle}°")

    start = time.time()
    mask_math, mask_vec = _mask_pair(w, h, center_x, center_y, a, b, angle)
    identical = np.array_equal(mask_math, mask_vec)
    print(f"\nMasks identical: {identical}")
    if not identical:
        diff = int((mask_math ^ mask_vec).sum())
        print(f"  Differences: {diff} pixels")

"""

def complete_pipeline(cells_data:    Dict) -> Tuple[np.ndarray, np.ndarray]:
    """Run the full generate -> save -> visualise pipeline on a toy dataset."""
    w, h = 128, 200
    if  cells_data is None:
        cells_data = {
            "indices":       list(range(1, 10)),
            "fluorescence":  [100, 120, 80, 150, 90, 110, 130, 140, 95],
            "size":          [15, 18, 14, 20, 16, 17, 19, 18, 15],
            "shape":         [(8, 19), (10, 13), (7, 6), (11, 7), (13, 8),
                               (9, 9), (11, 8), (45, 9), (18, 7)],
            "location":      [(30, 25), (30, 50), (40, 80), (60, 30),
                               (85, 70), (110, 25), (110, 85), (110, 110), (80, 110)],
            "rotation":      [0, 15, -20, 30, 0, 45, -10, 0, 25],
        }

    print("=== STEP 1: Generate canvas of uint8 labels ===")
    uint8_labels,   dimensions,    offset = generate_uint8_labels(w, h, cells_data)

    print("\n=== STEP 2: Save uint8 labels ===")
    metadata    =   save_uint8_labels(uint8_labels, dimensions, offset, "dump0\canvased_yeast_segmentation")
    cropped_uint8_labels  =   canvas_slicer(uint8_labels, dimensions, offset)

    save_uint8_labels(cropped_uint8_labels, dimensions, offset, "dump0\cropped_yeast_segmentation")

    print("\n=== STEP 3: Define and order colorMap to cells ===")
    thickness   =   10
    cells = np.array(range(0, len(cells_data["indices"]) + 1), dtype=np.uint8)
    colormap    =   colormap_for_cells(cells)
    strip = palette_to_strip(colormap, 200, thickness)

    print("\n=== STEP 4: Visualise ===")
    rgb_vis = visualize_uint8_labels(cropped_uint8_labels,metadata,colormap)
    imageio.imwrite("yeast_segmentation_visual.png", rgb_vis)
    print("Saved visualisation: yeast_segmentation_visual.png")

    return cropped_uint8_labels, rgb_vis

def canvas_slicer(canvas:   np.ndarray,dimensions:tuple,offset) -> np.ndarray:
    row_off, col_off = offset[0], offset[1]
    raster_h, raster_w = dimensions[0], dimensions[1]
    cropped =   canvas[row_off: row_off + raster_h,
                  col_off: col_off + raster_w]
    return cropped

def inspect_uint8_output(uint8_labels: np.ndarray) -> None:
    """Pretty‑print basic stats and a small patch of a label image."""
    print("=== Uint8 Label Array Inspection ===")
    print(f"Shape        : {uint8_labels.shape}")
    print(f"Data type    : {uint8_labels.dtype}")
    print(f"Memory       : {uint8_labels.nbytes} bytes")
    print(f"Min | Max    : {uint8_labels.min()} | {uint8_labels.max()}")

    unique, counts = np.unique(uint8_labels, return_counts=True)
    print("\nPixel counts per label:")
    for label, count in zip(unique, counts):
        tag = "Background" if label == 0 else f"Cell {label}"
        print(f"  {tag:11}: {count} px")

    print("\nSample (top‑left 10×10) of raw values:")
    print(uint8_labels[:10, :10])


#                                                                           -
# OpenCV‑BASED FAST FILL HELPER
#                                                                           -






if __name__ == "__main__":
    print("Running quick smoke tests for ellipse I/O + visualisation module…\n")

    # 1. Benchmark mathematical vs. vectorised
#    compare_mask_generation_methods()

    # 2. Full pipeline on toy dataset
    labels, rgb = complete_pipeline(None)
    inspect_uint8_output(labels)
    print("Demo RGB image saved as demo_labels_vis.png\n")
    #no more need for cv2
    """
    # 3. CV2 generator sanity check
    cv2_cells = {
        "indices": [1],
        "fluorescence": [0],
        "shape": [(25, 18)],
        "location": [(64, 64)],
        "rotation": [45],
    }
    cv2_labels,dimensions,offset = generate_uint8_labels_cv2(128, 128, cv2_cells)
    print("OpenCV generator produced label with unique values:", np.unique(cv2_labels))
    inspect_uint8_output(cv2_labels)
    print("All tests completed successfully.")
    """



    root = Path.cwd()  # same as os.getcwd()
    data_dir = root / "gold-standard-PhC-plus-2"  # cross‑platform join
    assert data_dir.is_dir(), f"{data_dir} does not exist"

    all_tifs = sorted(
        p for p in data_dir.glob("*.tif")  # pathlib.glob ≈ glob.glob
        if p.is_file()
    )
    print(f"Found {len(all_tifs)} TIFFs")

    # Ensure we have an even number of files
    if len(all_tifs) % 2:
        raise ValueError("Uneven number of TIFFs – check your directory!")

    pairs = [
        (all_tifs[i], all_tifs[i + 1])  # (mask, image)
        for i in range(0, len(all_tifs), 2)
    ]

    for mask_path, img_path in pairs:
        print("MASK :", mask_path.name)
        print("IMAGE:", img_path.name)
        # ─── load & process here ───


    def preview(mask_p, img_p, frame=0, alpha=0.4):
        # -------- load one frame --------
        mask = tiff.imread(mask_p)[frame]  # (H, W)  integer labels
        img = tiff.imread(img_p)[frame]  # (H, W) or (H, W, 3)

        # -------- prepare background --------
        if img.ndim == 3 and img.shape[-1] == 3:  #rgb -> luminance
            gray_img = rgb2gray(img)
        else:  #already grayscale
            gray_img = img.astype(np.float32)
            gray_img /= gray_img.max() or 1  # normalise 0‑1
        overlay = label2rgb(
            mask,  # keep IDs intact
            image=gray_img,
            bg_label=0,
            alpha=alpha  # transparencenter_y
        )

        overlay = np.clip(overlay, 0, 1)

        plt.figure(figsize=(6, 6))
        plt.imshow(overlay)
        plt.axis("off")
        plt.title(f"{mask_p.name} | frame {frame}")
        plt.show()



    # view the first pair
    preview(*pairs[0])
